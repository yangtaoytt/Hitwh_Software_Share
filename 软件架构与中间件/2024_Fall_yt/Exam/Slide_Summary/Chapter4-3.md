# Chapter-4-3

### 1. 缓存的概念，作用和原理

- **概念**
  1. 用于存储数据的硬件或软件组件，以使得后续更快访问响应的数据。
  2. 缓存中的数据可能是提前计算好的结果、数据的副本等。

- **作用**
  1. 主要解决高并发，热点数据访问的性能问题。
  2. 提供高性能的数据快速访问。

- **原理**
  1. 将数据写入到读取速度更快的存储
  2. 将数据缓存到离应用最近的位置
  3. 将数据缓存到离用户最近的位置

### 2. 数据缓存的存储介质分类

- **硬件介质上来看**：内存和硬盘
- **技术上**：内存，硬盘文件和数据库
  1. 内存：缓存于内存中是最快的选择，无需额外的I/O开销，但是内存的缺点是没有持久化到物理磁盘，一旦应用异常break down而重新启动，数据很难或者无法复原。
  2. 硬盘：一般来说，很多缓存框架会结合使用内存和硬盘，在内存分配空间满了或是在异常的情况下，可以被动或主动的将内存空间数据持久化到硬盘中，达到释放空间或备份数据的目的。
  3. 数据库：非传统数据库，而是key-value存储结构的特殊数据库（如BerkeleyDB和Redis），响应速度和吞吐量都远高于关系型数据库等。

### 3. 数据缓存的基本类型

1. 本地缓存
2. 分布式缓存
3. 反向代理缓存
4. CDN缓存

### 4. 本地缓存的定义，缺点，应用场景以及缓存介质和实现方法

- **定义**：本地缓存指的是在应用中的缓存组件，其最大的优点是应用和cache是在同一个进程内部，请求缓存非常快速，没有过多的网络开销等，在单应用不需要集群支持或者集群情况下各节点无需互相通知的场景下使用本地缓存较合适；

- **缺点**：因为缓存跟应用程序耦合，多个应用程序无法直接的共享缓存，各应用或集群的各节点都需要维护自己的单独缓存，对内存

  是一种浪费。

- **应用场景**：缓存字典等常用数据。

- **缓存介质**：

  1. 硬盘缓存：将数据缓存到硬盘，减少网络传输的消耗
  2. 内存缓存：直接将数据存储到本级内存中，通过程序直接维护缓存对象。

- **实现方法**：应用编码；中间件，如Ehcache、 Guava Cache等

### 5. 分布式缓存的定义，应用场景和常用中间件

- **定义**：分布式缓存指的是与应用分离的缓存组件或服务，其最大的优点是自身就是一个独立的应用，与本地应用隔离，多个应用可直接的共享缓存。
- **应用场景**：
  1. 缓存经过复杂运算得出的数据
  2. 缓存存储系统中频繁访问的热点数据，减轻存储系统压力

- **常用中间件**：Memcached，Redis

### 6. 反向代理缓存的定义，应用场景和开源实现

- **定义**：反向代理位于应用服务器机房，处理所有对WEB服务器的请求。如果用户请求的页面在代理服务器上有缓冲的话，代理服务器直接将缓冲内容发送给用户。如果没有缓冲则先向WEB服务器发出请求，取回数据，本地缓存后再发送给用户。通过降低向WEB服务器的请求数，从而降低了WEB服务器的负载。
- **应用场景**：一般只缓存体积较小的静态文件资源，如css、js、图片
- **开源实现**：Varnish，Nginx和Squid

### 7. CDN缓存的定义，目标和做法

- **定义**：CDN (Content Delivery Network)：内容分发网络。通过在现有互联网中增加一层新的网络架构（CDNS），将网站内容发布到最接近用户的网络“边缘”，使用户可以就近取得所需的内容。
- **目标**：解决由于网络带宽小、用户访问量大、网点分布不均等原因所造成的用户访问网站响应速度慢的问题。
- **做法**：将一个服务器的内容平均分布到多个服务器上；智能识别服务器，让用户获取离用户最近的服务器，提高访问速度。
  1. 分布式存储
  2. 负载均衡
  3. 网络请求的重定向
  4. 内容管理

### 8. 数据缓存的两个术语：命中列和最大元素/最大空间

- **命中率**
  1. 命中率=返回正确结果数/请求缓存次数
  2. 命中率问题是缓存中的一个非常重要的问题，它是衡量缓存有效性的重要指标。命中率越高，表明缓存的使用率越高。
  3. 缓存的管理者希望缓存命中率接近 100%。而实际得到的命中率则与缓存的大小、缓存用户兴趣点的相似性、缓存数据的变化或个性化频率，以及如何配置缓存有关。
  4. 命中率很难预测，但对现在中等规模的Web缓存来说，40%的命中率是很合理的。
- **最大元素**
  1. 缓存中可以存放的最大元素的数量，一旦缓存中元素数量超过这个值（或者缓存数据所占空间超过其最大支持空间），那么将会触发缓存启动清空策略
  2. 根据不同的场景合理的设置最大元素值往往可以一定程度上提高缓存的命中率，从而更有效的使用缓存。

### 9. HTTP再验证的定义，时机和实现

- **定义**：HTTP 再验证 (revalidation)：原始服务器的内容可能会发生变化，缓存要不时对其进行检测，看看它们保存的副本是否仍是服务器上最新的副本，进行“新鲜度检测”。
- **时机**：缓存可以在任意时刻，以任意的频率对副本进行再验证。但由于缓存中通常会包含数百万的文档，而且网络带宽是很珍贵的，所以大部分缓存只有在客户端发起请求，并且副本旧得足以需要检测的时候，才会对副本进行再验证。
- **实现**：
  1. 为了有效地进行再验证，HTTP 定义了一些特殊的请求，不用从服务器上获取整个对象，就可以快速检测出内容是否是最新的。
  2. HTTP 为我们提供了几个用来对已缓存对象进行再验证的工具，但最常用的是 If-Modified-Since 首部。将这个首部添加到 GET 请求中去，就可以告诉服务器，只有在缓存了对象的副本之后，又对其进行了修改的情况下，才发送此对象。

### 10. 服务器收到GET-if-modified-sience的3种情况

1. **再验证命中**(revalidate hit)或缓慢命中(slow hit)：如果服务器对象未被修改，服务器会向客户端发送一个小的 HTTP 304 Not Modified 响应。只要缓存知道副本仍然有效，就会再次将副本标识为暂时新鲜的，并将副本提供给客户端。
2. **再验证未命中**：如果服务器对象与已缓存副本不同，服务器向客户端发送一条普通的、带有完整内容的 HTTP 200 OK 响应。
3. **对象被删除**：如果服务器对象已经被删除了，服务器就回送一个 404 NotFound 响应，缓存也会将其副本删除。

### 11. 缓存清空策略的定义和分类

- **定义**：缓存清空策略：在缓存的存储空间有限制，当缓存空间被用满时，既要保证稳定服务，又要有效提升命中率。常见的一般策略有：

- **分类**：
  1. **FIFO**(first in first out)：先进先出策略，最先进入缓存的数据在缓存空间不够的情况下（超出最大元素限制）会被优先被清除掉，以腾出新的空间接受新的数据。策略算法主要比较缓存元素的创建时间。在数据实效性要求场景下可选择该类策略，优先保障最新数据可用。
  2. **LFU**(less frequently used)：最少使用策略，无论是否过期，根据元素的被使用次数判断，清除使用次数较少的元素释放空间。策略算法主要比较元素的hitCount（命中次数）。在保证高频数据有效性场景下，可选择这类策略。
  3. **LRU**(least recently used)：最近最少使用策略，无论是否过期，根据元素最后一次被使用的时间戳，清除最远使用时间戳的元素释放空间。策略算法主要比较元素最近一次被get使用时间。在热点数据场景下较适用，优先保证热点数据的有效性。
  4. 根据过期时间判断，清理过期时间最长的元素
  5. 根据过期时间判断，清理最近要过期的元素
  6. 随机清理
  7. 根据关键字（或元素内容）长短清理等

### 12. 数据缓存的更新策略分类

1. **Cache aside**
   1. 失效：应用程序先从cache取数据，没有得到，则从数据库中取数据，成功后，放到缓存中。
   2. 命中：应用程序从cache中取数据，取到后返回。
   3. 更新：先把数据存到数据库中，成功后，再让缓存失效。
2. **Read/Write Through Pattern**
   1. Read Through 是在查询操作中更新缓存，也就是说，当缓存失效的时候（过期或LRU换出），Cache Aside是由调用方负责把数据加载入缓存，而Read Through则用缓存服务自己来加载，从而对应用方是透明的。
   2. Write Through 在更新数据时发生。当有数据更新的时候，如果没有命中缓存，直接更新数据库，然后返回。如果命中了缓存，则更新缓存，然后再由Cache自己更新数据库（这是一个同步操作）。
3. **Write Behind Caching Pattern**
   1. 俗称write back，在更新数据的时候，只更新缓存，不更新数据库，而我们的缓存会异步地批量更新数据库。这个设计的好处就是让数据的I/O操作飞快无比，因为异步（比如消息队列），write back还可以合并对同一个数据的多次操作，所以性能的提高是相当可观的。
   2. 但是这个设计的最大致命问题在于数据的非强一致性，极可能造成数据的丢失。假如使用redis作为缓存数据库，最致命的问题在于redis并不能保证绝对不丢失数据，也就是redis的持久化能力（两种持久化都无法保证数据绝对丢失）不足，redis一旦挂了，可能造成数据丢失且无法恢复。

### 13. 本地缓存的实现方法分类

1. **编程直接实现**

   1. 成员变量或局部变量实现。以局部变量map结构缓存部分业务数据，减少频繁的重复数据库I/O操作。缺点仅限于类的自身

      作用域内，类间无法共享缓存。

   2. 静态变量实现

2. 中间件**Ehcache**

   1. Ehcache是现在最流行的纯Java开源缓存框架，配置简单、结构清晰、功能强大，是一个轻量级的缓存实现，Hibernate里面集成了相关缓存功能。

   2. Ehcache的核心定义主要包括：

      1. cache manager：缓存管理器，允许多实例

      2. cache：缓存管理器内可以放置若干cache，存放数据的实质，所有cache都实现了

         Ehcache接口，这是一个真正使用的缓存实例；通过缓存管理器的模式，可以在单个应用中

         轻松隔离多个缓存实例，独立服务于不同业务场景需求，缓存数据物理隔离，同时需要时

         又可共享使用。

### 14. 分布式缓存的迁移

1. 平滑迁移
2. 一致性哈希
3. 停机迁移

### 15. 一致性哈希的做法

1. 一致性哈希将整个哈希值空间组织成一个虚拟的圆环（哈希环）。
2. 将各个服务器使用Hash进行一个哈希，具体可以选择服务器的ip或主机名作为关键字进行哈希，这样每台机器就能确定其在哈希环上的位置
3. 将数据key使用相同的函数Hash计算出哈希值，并确定此数据在环上的位置，从此位置沿环顺时针“行走” ，第一台遇到的服务器就是其应该定位到的服务器

### 16. 平滑迁移的做法

#### 1. **双写**

- **目标**：同时向旧缓存和新缓存写数据。
- **实现**：在迁移过程中，依旧使用旧的路由规则（如关键字哈希除以2取余），同时应用新的规则（关键字哈希除以4取余）将数据写入到新的缓存集群。此时，前两个新的分片可以重用旧缓存分片的数据，而只新增两个分片处理新的数据。

#### 2. **迁移历史数据**

- **目标**：将旧缓存中的历史数据迁移到新的缓存集群。
- **实现**：将历史数据按新的规则写入新集群。这一过程中可能需要开发迁移工具，并验证数据迁移的成功。
- **优化**：在某些情况下，如果缓存数据并非强依赖或具有时效性，可以不迁移旧数据，依靠新数据逐步替代。

#### 3. **切读**

- **目标**：将所有读操作转移到新的缓存集群。
- **实现**：这一步骤通过切换读取逻辑，将应用中的缓存读取操作改为从新的集群获取。通常无需修改应用代码，只需切换读取开关。

#### 4. **下线双写**

- **目标**：停用向旧缓存集群写数据的逻辑。
- **实现**：当确认新缓存集群的读写正常并且数据一致性没有问题时，下线双写操作，并清理旧的缓存分片中的冗余数据。

### 17. 一致性哈希的容错性和可扩展性

1. 现假设Node C不幸宕机，可以看到此时对象A、B、D不会受到影响，只有C对象被重定位到Node D。一般的，在一致性哈希算法中，如果一台服务器不可用，则受影响的数据仅仅是此服务器到其环空间中前一台服务器（即沿着逆时针方向行走遇到的第一台服务器）之间数据，其它不会受到影响。
2. 如果在系统中增加一台服务器NodeX，此时对象Object A、B、D不受影响，只有对象C需要重定位到新的Node X 。一般的，在一致性哈希算法中，如果增加一台服务器，则受影响的数据仅仅是新服务器到其环空间中前一台服务器（即沿着逆时针方向行走遇到的第一台服务器）之间数据，其它数据也不会受到影响。

### 18. 一致性哈希的缺点和解决办法

- **缺点**：一致性哈希算法在服务节点太少时，容易因为节点分布不均匀而造成数据倾斜问题。此时必然造成大量数据集中到一个节点上。
- **解决办法**：为了解决这种数据倾斜问题，一致性哈希算法引入了虚拟节点机制，即对每一个服务节点计算多个哈希，每个计算结果位置都放置一个此服务节点，称为虚拟节点。

### 19. 停机迁移的做法及评价

- **做法**
  1. 停机应用，先将应用停止服务
  2. 迁移历史数据，按照新的规则把历史数据迁移到新的缓存数据集群中
  3. 更改应用的数据源配置，指向新的缓存集群
  4. 重新启动应用
- **评价**：该方式简单，高效，能够有效避免数据的不一致，但需要由业务方评估影响，一般在晚上访问量较小，或者非核心服务的场景下比较适用。

### 20. 缓存导致的问题

1. 数据一致性
2. 缓存穿透
3. 缓存雪崩
4. 缓存高可用
5. 缓存热点

### 21. 数据一致性问题的原因和解决办法

- **原因**：因为缓存属于持久化数据的一个副本，所以不可避免的会出现数据不一致问题，如脏读或读不到数据的情况。
- **解决办法**
  1. 先写缓存，再写数据库：【描述】缓存写成功，但写数据库失败或响应延迟，则下次读取（并发读）缓存时，就出现脏读；【解决】这个写缓存的方式，本身就是错误的，需要改为先写持久化介质，再写缓存的方式
  2. 先写数据库，再写缓存：【描述】写数据库成功，但写缓存失败，则下次读取（并发读）缓存时，则读不到数据；【解决1】根据写入缓存的响应来进行判断，如果缓存写入失败，则回滚数据库操作。该方法增加了程序的复杂度；【解决2】缓存使用时，假如读缓存失败，先读数据库，再回写缓存
  3. 缓存异步刷新：【描述】指数据库操作和写缓存不在一个操作步骤中，比如在分布式场景下，无法做到同时写缓存或需要异步刷新；【解决】根据日志中用户刷新数据的时间间隔，以及针对数据可能产生不一致的时间，进行同步操作

### 22. 缓存穿透的原因和解决办法

- **原因**：缓存穿透指的是使用不存在的key进行大量的高并发查询，这导致缓存无法命中，每次请求都要穿透到后端数据库系统进行查询，使得数据库压力过大，甚至导致数据库服务崩溃。
- **解决办法**
  1. 通常将空值缓存起来，再次接收到同样的查询请求时，若命中缓存并值为空，就会直接返回，不会透传到数据库，避免缓存穿透
  2. 对恶意的查询攻击，可以对查询条件设置规则，不符合条件产生规则的直接拒绝

### 23. 缓存并发的原因和解决办法

- **原因**：缓存并发的问题通常发生在高并发的场景下，当一个缓存key过期时，因为访问这个缓存key的请求量较大，多个请求同时发现缓存过期，因此多个请求会同时访问数据库来查询最新数据，并且回写缓存，这样会造成应用和数据库的负载增加，性能降低，由于并发较高，甚至会导致数据库崩溃。

- 解决办法

  1. **分布式锁**：使用分布式锁，保证对于每个key同时只有一个线程去查询后端服务，其他线程没有获得分布式锁的权限，因此只需要等待即可。该方式将高并发的压力转移到了分布式锁，因此对分布式锁的考验很大。

  2. **本地锁**：与分布式锁类似，通过本地锁的方式来限制只有一个线程去数据库中查询数据，而其他线程只需等待，等前面的线程查询到数据后再访问缓存。但是，这种方法只能限制一个服务节点只有一个线程取数据库中查询，如果一个服务有多个节点，则会有多个数据库查询操作，也就是说在节点数量较多的情况下并没有完全解决缓存并发的问题。

  3. **软过期**：（1）软过期指对缓存中的数据设置失效时间，就是不使用缓存服务提供的过期时间，而是业务层在数据中存储过期时间信息，由业务程序判断是否过期并更新，在发现了数据即将过期时，将缓存的时效延长，程序可以派遣一个线程去数据库中获取最新的数据，其他线程会先继续使用旧数据并等待，直至派遣线程获取最新数据后再更新缓存。（2）也可以通过异步更新服务来更新设置软过期的缓存，这样应用层就不用关心缓

     存并发的问题。

### 24. 缓存雪崩的原因和解决办法

- **原因**：缓存雪崩指缓存服务器重启或者大量缓存集中在某一个时间段内失效，业务系统需要重新生成缓存，给后端数据库造成瞬时负载升高的压力，甚至导致数据库崩溃。
- **解决办法**
  1. 更新锁机制：对缓存更新操作进行加锁保护，保证只有一个线程能进行缓存更新
  2. 失效时间分片机制：对不同的数据使用不同的失效时间，甚至对相同的数据、不同的请求使用不同的失效时间
  3. 后台更新机制：由后台线程来更新缓存，并不是业务线程来更新缓存。（1）后台线程除了定时更新缓存，还要频繁去读取缓存（2）业务线程发现缓存失效后，通过消息队列发送一条消息通知后台线程更新缓存（适合业务刚上线时缓存预热）
  4. 缓存集群：可以做缓存的主从与缓存水平分片

### 25. 缓存热点的原因和解决办法

- **原因**：一些特别热点的数据，高并发访问同一份缓存数据，导致缓存服务器压力过大。
- **解决办法**：复制多份缓存副本，把请求分散到多个缓存服务器上，减轻缓存热点导致的单台缓存服务器压力